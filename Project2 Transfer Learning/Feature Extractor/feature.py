# -*- coding: utf-8 -*-
"""feature.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ySrt9z3GC-css7dAZi2QBl7GivfhHPRJ
"""

from google.colab import drive
drive.mount('/content/drive')

from __future__ import print_function 
from __future__ import division
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import copy
print("PyTorch Version: ",torch.__version__)
print("Torchvision Version: ",torchvision.__version__)

import torch
torch.cuda.is_available()

def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=45, is_inception=False):
    since = time.time()

    test_acc_history = []

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)
        

        # Each epoch has a training and validation phase
        for phase in ['train', 'test']:
            if phase == 'train':
                model.train()  # Set model to training mode
               
            else:
                model.eval()   # Set model to evaluate mode 
            
            running_loss = 0.0
            running_corrects = 0
            

            # Iterate over data.
            print(dataloaders)
            for inputs, labels in (dataloaders[phase]):         #image in inputs .. 9 vectors in label  
                inputs = inputs.to(device)
                labels = labels.to(device)              
                
                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                   
                    if is_inception and phase == 'train':
                        
                        outputs, aux_outputs = model(inputs)
                        loss1 = criterion(outputs, labels)
                        loss2 = criterion(aux_outputs, labels)
                        loss = loss1 + 0.4*loss2
                        loss.backward()
                        optimizer.step()
                    
                    else:
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)
                        
                    _, preds = torch.max(outputs, 1)
                        
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc =  running_corrects.float() / len(dataloaders[phase].dataset)

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

            # deep copy the model
            if phase == 'test' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
            if phase == 'test':
                test_acc_history.append(epoch_acc)

        print()

    time_elapsed = time.time() - since
    print('Training complete in {:.2f}m {:.2f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best test Acc: {:4f}'.format(best_acc))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model, test_acc_history

feature_extract= True

def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        for param in model.parameters():
            param.requires_grad = False

model_name= "inception"
feature_extract= True
num_classes=9
def initialize_model(model_name, num_classes, feature_extract):
    # Initialize these variables which will be set in this if statement. Each of these
    #   variables is model specific.
    
    input_size = 299

    if model_name == "inception":
        
        model_ft = models.inception_v3(pretrained=True, progress=True)
        set_parameter_requires_grad(model_ft, feature_extract)
        # Handle the auxilary net
        num_ftrs = model_ft.AuxLogits.fc.in_features
        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)  #changed from num_classes
        # Handle the primary net
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs,num_classes)           #changed from num_classes
        input_size = 299
        

    else:
        print("Invalid model name, exiting...")
        exit()
    
    return model_ft, input_size

    # Initialize the model for this run
model_ft, input_size = initialize_model(model_name, num_classes, feature_extract)

# Print the model we just instantiated
print(model_ft)

test_path="/content/drive/My Drive/Project DIVP/places/test"
train_path="/content/drive/My Drive/Project DIVP/places/train"
path={'train':'/content/drive/My Drive/Project DIVP/places/train','test':'/content/drive/My Drive/Project DIVP/places/test'}
data_transforms = {
    'train': transforms.Compose([
        transforms.CenterCrop(10),                         
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.Resize((299, 299)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.CenterCrop(224),
        transforms.Resize((299, 299)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

image_dataset = {x:datasets.ImageFolder(path[x], data_transforms[x]) for x in ['train', 'test']}
dataloaders = {x:torch.utils.data.DataLoader(image_dataset[x], batch_size=10, shuffle=True, num_workers=2) for x in ['train', 'test']}

classes = ('abbey', 'airpot_terminal', 'alley', 'amphittheater', 'amusement_park'
           'aquarium', 'aqueduct', 'arch', 'art_gallery')

params_to_update = model_ft.parameters()
print("Params to learn:")
if feature_extract:
    params_to_update = []
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            params_to_update.append(param)
            print("\t",name)
else:
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            print("\t",name)

optimizer_ft = optim.SGD(params_to_update, lr=1e-4, momentum=0.9)

# Setup the loss fxn
criterion = nn.CrossEntropyLoss()

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_ft = model_ft.to(device) #send the model to the gpu
model_name="inception"

# Train and evaluate
model_ft, hist = train_model(model_ft, dataloaders, criterion, optimizer_ft, device, num_epochs=45, is_inception=(model_name=="inception") )

# torch.save(model_ft.state_dict(), '/content/drive/My Drive/Project DIVP/feature.pt')
torch.save(model_ft, '/content/drive/My Drive/Project DIVP/feature.pt')

from PIL import Image


# model_ft = models.inception_v3(pretrained=False, progress=True)
# model_ft.load_state_dict(torch.load('/content/drive/My Drive/Project DIVP/feature.pt'))
# model_ft.eval()
device = torch.device("cuda")
model=torch.load('/content/drive/My Drive/Project DIVP/feature.pt')
model.to(device)
# model.eval()
# model.cuda()
validation_img_paths = ["/abbey/gsun_21c6a81a76ec855edb1628eeefbea895.jpg",
                        "/alley/gsun_1216340169b4383483519ffc3ed0016f.jpg",
                        "/amusement_park/gsun_1d227b4dcfee71cc0030b631bfd7bed0.jpg",
                        "/aquarium/gsun_0e18c83cc5c481a24d0ddf7bf201b346.jpg"]
img_list = [Image.open(test_path + img_path) for img_path in validation_img_paths]

from torch.nn import functional as F
# device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# model_ft = model_ft.to(device)
validation_batch = torch.stack([data_transforms['test'](img).to(device)
                                for img in img_list])

pred_logits_tensor = model(validation_batch)
print(pred_logits_tensor)

# pred_probs = nn.Softmax(pred_logits_tensor.logits).cuda()
# pred_probs=pred_probs.dim
pred_probs = torch.nn.functional.softmax(pred_logits_tensor, dim=1)
pred_probs
print(pred_probs)

import pandas as pd
fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))
for i, img in enumerate(img_list):
    ax = axs[i]
    #d= pd.DataFrame()
    #p = list(pred_probs*100)
    #d=d.append(p) 
    #print(d.loc[:,0:0]) 
    print(100*pred_probs[i,0])
    ax.set_title("{:.0f}% abbey \n {:.0f}% airpot_terminal \n {:.0f}% alley \n {:.0f}% amphitheater \n {:.0f}% amusement_park \n {:.0f}% aquarium \n {:.0f}% aqueduct \n {:.0f}% arch \n {:.0f}% art_gallery \n".format( 100*pred_probs[i,0],
                                                                                                                                                                                                                         100*pred_probs[i,1],
                                                                                                                                                                                                                         100*pred_probs[i,2],
                                                                                                                                                                                                                         100*pred_probs[i,3],
                                                                                                                                                                                                                         100*pred_probs[i,4],
                                                                                                                                                                                                                         100*pred_probs[i,5],
                                                                                                                                                                                                                         100*pred_probs[i,6],
                                                                                                                                                                                                                         100*pred_probs[i,7],
                                                                                                                                                                                                                         100*pred_probs[i,8]))
    

    ax.imshow(img)

import itertools
import numpy as np
import matplotlib.pyplot as plt

from sklearn import svm, datasets
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
nb_classes = 9
c=[]
confusion_matrix = torch.zeros(nb_classes, nb_classes)

def plot_confusion_matrix(cm,y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    # cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    # classes = classes[unique_labels(y_true, y_pred)]
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax
with torch.no_grad():
    for i, (inputs, classes) in enumerate(dataloaders['test']):
        inputs = inputs.to(device)
        classes = classes.to(device)
        c.append(classes)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        # print(preds)
        for t, p in zip(classes.view(-1), preds.view(-1)):
                confusion_matrix[t.long(), p.long()] += 1
cm=np.asarray(confusion_matrix)
cm=cm.astype(int)    
plt.figure(figsize=(20,10))
# plt.tight_layout(pad=2,h_pad=4, w_pad=3, rect=(0,0,5,5))
plot_confusion_matrix(cm,c,preds, classes=['abbey', 'airpot_terminal', 'alley', 'amphittheater','amusement_park',
           'aquarium', 'aqueduct', 'arch', 'art_gallery'],normalize=True)
plt.show()